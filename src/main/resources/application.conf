kafka {
  input {
    topic="source"
    zookeeper="localhost:2181"
    broker="localhost:9092"
  }
  output {
    zookeeper="localhost:2181"
    broker="localhost:9092"
  }
  monitor {
    topic="spark_data_streaming_monitor"
    zookeeper="localhost:2181"
    broker="localhost:9092"
  }

  maxOffsetsPerTrigger = 50000
  retries = 1000
  retryBackoffMs = 500
  fetchOffsetNumRetries = 1000
  fetchOffsetRetryIntervalMs = 1000
  metadataFetchTimeoutMs = 600000

}

cassandra {
  host = "localhost"
  keyspace = "ks_global_pda"
  username = ""
  password = ""
  detailsTableName = "spark_data"
  aggregatesTableName = "spark_agg"
}

spark {
  checkpointLocation = "/tmp/spark_data_stream/checkpoint/"
  outputLocation = "/tmp/spark_data_stream/output/"
  cassandraOutputConsistencyLevel = "LOCAL_ONE"
  streamingStopGracefullyOnShutdown = true
  streamingBackpressureEnabled = true
  streamingBackpressureInitialRate = 50000
  streamngKafkaMaxRatePerPartition = 50000
  streamngTriggerWindow = "600 seconds"
  logLevel = "INFO"
}