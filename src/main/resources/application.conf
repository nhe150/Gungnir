kafka {
  input {
    topic="source"
    zookeeper="localhost:2181"
    broker="localhost:9092"
  }
  output {
    zookeeper="localhost:2181"
    broker="localhost:9092"
  }
  monitor {
    //BTS
    topic="bt1_spark_streaming_monitor"
    //Production
    //topic="sj1_spark_streaming_monitor"
    zookeeper="localhost:2181"
    broker="localhost:9092"
  }

  //BTS
  topicPrefix = "bt1_spark_"
  //production
  //topicPrefix = "sj1_spark_"

  topicPostfix = "_hdfs"
  maxOffsetsPerTrigger = 5000000
  retries = 1000
  retryBackoffMs = 500
  fetchOffsetNumRetries = 1000
  fetchOffsetRetryIntervalMs = 1000
  metadataFetchTimeoutMs = 600000
  lingerMs = 3000
  batchSize = 163840
  timeoutMs = 300000
  requestTimeoutMs = 300000
  maxRequestSize = 104857600
}

cassandra {
  host = "localhost"
  keyspace = "ks_global_pda"
  keyspace_global = "ks_global_pda"
  keyspace_amer   = "ks_amer_pda"
  keyspace_emea   = "ks_emea_pda"
  keyspace_apac   = "ks_apac_pda"
  username = ""
  password = ""
  detailsTableName = "spark_data"
  aggregatesTableName = "spark_agg"
  licenseTableName = "license"
}

spark {
  checkpointLocation = "/tmp/spark_data_stream/checkpoint/"
  outputLocation = "/tmp/spark_data_stream/output/"
  cassandraOutputConsistencyLevel = "LOCAL_ONE"
  streamingStopGracefullyOnShutdown = true
  streamingBackpressureEnabled = true
  streamingBackpressureInitialRate = 5000000
  streamngKafkaMaxRatePerPartition = 5000000
  streamingKafkaFailOnDataLoss = true
  streamngTriggerWindow = "60 seconds"
  saveToFileTriggerWindow = "600 seconds"
  logLevel = "INFO"
}