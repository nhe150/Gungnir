kafka {
  input {
    topic="source"
    zookeeper="localhost:2181"
    broker="localhost:9092"
  }
  output {
    #zookeeper="localhost:2181"
    #broker="localhost:9092"
    zookeeper="rpbt1hmn003.webex.com:2181"
    broker="bt1-kafka-s.webex.com:9092"
  }
  monitor {
    topic="spark_data_streaming_monitor"
    zookeeper="localhost:2181"
    broker="localhost:9092"
  }

  maxOffsetsPerTrigger = 5000000
  retries = 1000
  retryBackoffMs = 500
  fetchOffsetNumRetries = 1000
  fetchOffsetRetryIntervalMs = 1000
  metadataFetchTimeoutMs = 600000
  lingerMs = 3000
  batchSize = 163840
  timeoutMs = 300000
  requestTimeoutMs = 300000
  maxRequestSize = 104857600
}

cassandra {
  host = "10.225.4.178"
  keyspace = "ks_global_pda"
  username = "cassandra"
  password = "cassandra"
  detailsTableName = "spark_data"
  aggregatesTableName = "spark_agg"
}

spark {
  checkpointLocation = "/tmp/spark_data_stream/checkpoint/"
  outputLocation = "/tmp/spark_data_stream/output/"
  cassandraOutputConsistencyLevel = "LOCAL_ONE"
  streamingStopGracefullyOnShutdown = true
  streamingBackpressureEnabled = true
  streamingBackpressureInitialRate = 5000000
  streamngKafkaMaxRatePerPartition = 5000000
  streamngTriggerWindow = "60 seconds"
  logLevel = "INFO"
}